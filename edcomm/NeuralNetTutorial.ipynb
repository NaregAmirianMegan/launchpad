{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks with MNIST\n",
    "\n",
    "### In this notebook we build a neural network to predict the value of handwritten digits:\n",
    "<img src=\"https://tensorflow.rstudio.com/tensorflow/articles/images/MNIST.png\"\n",
    "     alt=\"Image Didn't Load\"\n",
    "     style=\"float: left; margin-right: 10px;\" />  \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "### We're going to use a network that looks like this:\n",
    "![](./images/tf_vis.png)  \n",
    "\n",
    "### Network structure\n",
    "We will take in all 28 * 28 pixel values from each image (these are grayscale images so we don't have to worry about color channels). The inputs will be multiplied by the weights of each layer and put through the activation function called ReLU (Rectified Linear Unit). The output will be a probability distribution over ten numbers (0,...,9) indicating the probability that each digit is the number in the image.\n",
    "\n",
    "![](./images/net_vis.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "# import MNIST (MNIST is a dataset containing correctly labeled images of handwritten numbers)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#import pyplot for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Create a variable containing MNIST data\n",
    "# There's more than 30,000 images here \n",
    "# Just imagine the man hours :P\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "# Ignore the warnings :P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting hyperparameters \n",
    "This is where we specify how we want our network to \"look\" and behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much of a step we take. Higher learning rates means faster learning but less stable performance\n",
    "learning_rate = 0.001 \n",
    "\n",
    "# How many images we are training on at every step. \n",
    "# Remember this is gradient descent so we are gonna take small steps of just 128 images towards the goal\n",
    "batch_size = 128\n",
    "\n",
    "# run 2000 steps\n",
    "n_steps = 200\n",
    "\n",
    "# How many neurons for each layer\n",
    "n_inputs = 28 * 28 # its a 28 by 28 pixel image so input is gonna be 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_output = 10 # output is probabilities of the image being a particular number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "In a tensorflow graph we create placeholders which upon running the graph will contain our input and output data (i.e. images and associated digits each one represents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create placeholders\n",
    "# this is where we will feed in the images and the labels\n",
    "# x is where we will feed in the image\n",
    "x = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "# y is where we will feed in the label for the corresponding image\n",
    "# i.e. if the image is a 3, y is 3\n",
    "y = tf.placeholder(tf.int64, shape=None, name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the actual network\n",
    "After the input layer we have three more layers: hidden layer 1, hidden layer 2, and the output layer. Here we will use tf.layers.dense(inputs, units, activation) -- <b>inputs</b> is the input to the layer, <b>units</b> is the number of nodes in that layer, and <b>activation</b> is the activation function applied in that layer (no activation if left blank). Remember that we want to use the ReLU function (https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/). \n",
    "<br>\n",
    "<b>ReLU</b>:\n",
    "\n",
    "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/Line-Plot-of-Rectified-Linear-Activation-for-Negative-and-Positive-Inputs.png\"\n",
    "     alt=\"Image Didn't Load\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the neural network\n",
    "# hidden1 layer takes in our image input (x)\n",
    "# we will be using the relu activation function\n",
    "\n",
    "hidden1_layer = tf.layers.dense(x, n_hidden1, activation=tf.nn.relu)\n",
    "hidden2_layer = tf.layers.dense(hidden1_layer, n_hidden2, activation=tf.nn.relu)\n",
    "output_layer = tf.layers.dense(hidden2_layer, n_output)\n",
    "\n",
    "# if you get some weird error about reuse, restart the kernel\n",
    "\n",
    "# for more about activation functions:\n",
    "# https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "Here we will be using cross entropy get our error which is a way to determine how close our probability distribution is to the ground truth probability distribution (i.e. a one-hot vector with the one in index corresponding to the correct digit of the related image). We then want to reduce our error over each element in the batch to one error. More on cross entropy: https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/. \n",
    "\n",
    "<br>\n",
    "<b>Cross Entropy:</b><br>\n",
    "p(x) is 0 or 1 indicating the correct \"class\" or not; q(x) is our predicted probability; for each x in (0,...,9)\n",
    "<img src=\"http://4.bp.blogspot.com/-O5gRO-nJIQc/WacXCgSMdxI/AAAAAAAA6Gw/ReT-cKX0MM0BYiDXJ9JJ_WFBzcBluvgqwCK4BGAYYCw/s1600/cross%2Bentropy.png\"\n",
    "     alt=\"Image Didn't Load\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# instead of using squared error like the 3Blue1Brown video, we use cross entropy error\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=output_layer)\n",
    "\n",
    "# add up all the error with reduce_mean\n",
    "loss = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the training operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use Adam Optimizer to do all the backpropagation heavy lifting for us\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# create an operator that we can call on to minimize loss\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create operators for evaluating the network\n",
    "with tf.name_scope(\"eval\"):\n",
    "    # correct variable is the number of correct labels\n",
    "    correct = tf.nn.in_top_k(output_layer, y, 1)\n",
    "    # count up the number of correct labels\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the session and running the graph\n",
    "Now that we have our data, network, hyperparameters, etc... we want to actually train the network so it outputs values that are correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.189\n",
      "50 Test accuracy: 0.8958\n",
      "100 Test accuracy: 0.9249\n",
      "150 Test accuracy: 0.937\n"
     ]
    }
   ],
   "source": [
    "# creates a tensorflow session\n",
    "# the session will keep all of our values and current state of the network\n",
    "sess = tf.Session()\n",
    "    \n",
    "# first initialize the values in the network\n",
    "tf.global_variables_initializer().run(session=sess)\n",
    "\n",
    "for step in range(n_steps):\n",
    "    # creates a batch of images and labels\n",
    "    x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "    # feed in the batch of images and batch of labels\n",
    "    # and run the training operator on them\n",
    "    sess.run(training_op, feed_dict={x: x_batch, y: y_batch})\n",
    "\n",
    "    # feed in the test images and the test labels (which the network has never seen)\n",
    "    # and evaluate the accuracy\n",
    "    accuracy_val = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "\n",
    "    if step % 50 == 0:\n",
    "        print(step, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12683a748>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "#get visualization\n",
    "image = mnist.train.next_batch(1)[0]\n",
    "plt.imshow(np.reshape(image, (28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.2036906e-05 5.9247399e-05 4.0936747e-04 6.6588619e-03 3.8132450e-06\n",
      " 1.5065038e-04 3.9823124e-07 9.8992854e-01 9.8589226e-05 2.5985767e-03]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show bar plot of probabilites\n",
    "probs = softmax(sess.run(output_layer, feed_dict={x: image})[0])\n",
    "print(probs)\n",
    "x_pos = [i for i, _ in enumerate(probs)]\n",
    "plt.bar(x_pos, probs, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close session\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
